{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from flatten_json import flatten\n",
    "import pickle\n",
    "from hx_lib import *\n",
    "from hx_tools import *\n",
    "user_id = USER_ID\n",
    "pwd = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hx_get_hosts(hx):\n",
    "    # Use either aws or local to signify the appliance to be used.\n",
    "    if hx == 'aws':\n",
    "        hx_appliance = AWS_SVR\n",
    "    elif hx == 'local':\n",
    "        hx_appliance = LOCAL_SVR\n",
    "    # Then makes a call to an underlying class (HXAPI) to log into the designated appliance.\n",
    "    hx_api_object = HXAPI(hx_appliance, hx_port = 3000)\n",
    "    (ret, response_code, response_data) = hx_api_object.restLogin(user_id, pwd)\n",
    "    hresponse_data = {}\n",
    "    # If the login is successful, get records for all agents. In this case, with an upper limit of 150k records.\n",
    "    if ret:\n",
    "        (ret, hresponse_code, hresponse_data) = hx_api_object.restListHosts(limit=150000)\n",
    "        return ret, hresponse_code, hresponse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes API call to stores results in 'results' variable\n",
    "results = hx_get_hosts(hx='eag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store just the actual records and not the extraneous information returned in the original API results.\n",
    "data = (results[2]['data']['entries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the returned API results\n",
    "hosts_df = pd.json_normalize(data, max_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify column names of the DataFrame\n",
    "print(list(hosts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "hosts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Version Pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table to divide agents into OS type then to display the agent versions, counts for each version, and a total agent count.\n",
    "agent_pivot = pd.pivot_table(hosts_df.fillna(0), index=['os.platform', 'agent_version'], aggfunc='count', margins = True)\n",
    "agent_df = agent_pivot['_id']\n",
    "agent_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent OS Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table to divide agents into OS type and then into OS versions and counts of each with a total.\n",
    "pd.options.display.max_rows = 100\n",
    "os_pivot = pd.pivot_table(hosts_df.fillna(0), index=['os.platform', 'os.product_name'], aggfunc='count', margins = True)\n",
    "os_df = os_pivot['_id']\n",
    "os_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Excel document with a tab for the DataFrame and a tab for the Pivot Table\n",
    "writer = pd.ExcelWriter('FireEye OS Breakdown.xlsx', engine='xlsxwriter')\n",
    "agent_df.to_excel(writer, 'OS Pivot Table')\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with the OS as the index\n",
    "agent_df = agent_df.to_frame()\n",
    "agent_df_indexed = agent_df.reset_index(level=['os.product_name'])\n",
    "agent_df_indexed\n",
    "\n",
    "# storing agent pivot table permanently\n",
    "agent_df_currentdate = agent_df\n",
    "%store agent_df_currentdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pickle file that was previously saved\n",
    "fireeye_df_previousdate = pickle.load( open( \"fireeye_df_previousdate.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "fireeye_df_previousdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort agent records in DataFrame by date of last agent checkin, oldest to newest\n",
    "sorted_fireeye_previousdate = fireeye_df_previousdate.sort_values(by='LAST_POLL_TIMESTAMP', ascending=False)\n",
    "sorted_fireeye_previousdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deduplicate the agents, only keeping the oldest record\n",
    "dedupe_fe_currentdate = sorted_fireeye_currentdate.drop_duplicates(subset=['HOSTNAME'], keep='first')\n",
    "dedupe_fe_currentdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pivot table to divide agents into OS type then to display the agent versions, counts for each version, and a total agent count.\n",
    "agent_pivot_currentdate = pd.pivot_table(dedupe_fe_currentdate.fillna(0), index=['os.platform', 'AGENT_VERSION'], aggfunc='count', margins = True)\n",
    "agent_df_currentdate = agent_pivot_currentdate['_ID']\n",
    "agent_df_currentdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset the index of the DataFrame and create new variable to store these changes.\n",
    "agent_df_currentdate_indexed = agent_df_currentdate.reset_index(level='AGENT_VERSION')\n",
    "agent_df_currentdate_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(type(agent_df_currentdate))\n",
    "# test_df = test_df.to_frame()\n",
    "agent_df_currentdate_indexed['AGENT_VERSION'] == agent_df_previousdate_indexed['AGENT_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shape of the current DataFrame\n",
    "agent_df_currentdate_indexed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get shape of previous DataFrame to compare with current DataFrame for a sanity check\n",
    "agent_df_previousdate_indexed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df_currentdate_indexed.compare(agent_df_previousdate_indexed, keep_equal=True, keep_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df_currentdate_comparison = agent_df_currentdate_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df_currentdate_comparison['Current Count'] = agent_df_previousdate_indexed['_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data to be graphed\n",
    "agent_graph_ready = agent_df_currentdate_indexed_test\n",
    "agent_graph_ready = agent_graph_ready.iloc[:-1 , :]\n",
    "# agent_graph_ready = agent_graph_ready.drop(columns=['Delta'])\n",
    "agent_graph_ready = agent_graph_ready.rename(columns={\"_ID\": \"1-5-2022 Count\"})\n",
    "agent_graph_ready= agent_graph_ready.reset_index()\n",
    "agent_graph_ready = agent_graph_ready.set_index(['os.platform', 'AGENT_VERSION'])\n",
    "agent_graph_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "agent_graph_ready.plot(figsize=(20,10),logy=True, kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the previous data with the current data and show the change (Delta column) between the 2 dates\n",
    "agent_df_currentdate_indexed_test['Delta'] = agent_df_currentdate_indexed_test['_ID'].sub(agent_df_currentdate_indexed_test['1-10-2020 Count'], axis = 0)\n",
    "agent_df_currentdate_indexed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Excel document and create a tab for each of the DataFrames created\n",
    "writer = pd.ExcelWriter('FireEye Agent Version Breakdown.xlsx', engine='xlsxwriter')\n",
    "raw_pivot.to_excel(writer, 'Pivot Tables', startcol=0)\n",
    "mac_pivot.to_excel(writer, 'Pivot Tables', startcol=4)\n",
    "agent_df_currentdate.to_excel(writer, '1-5-2023 Agent Breakdown')\n",
    "agent_df_01102022.to_excel(writer, '1-10-2023 Agent Breakdown')\n",
    "agent_df_01312022.to_excel(writer, '1-10-2023 Agent Breakdown')\n",
    "linux_agents.to_excel(writer, 'Linux Servers', index=False)\n",
    "win_servers.to_excel(writer, 'Windows Servers', index=False)\n",
    "workstations.to_excel(writer, 'All Workstations', index=False)\n",
    "win_workstations.to_excel(writer, 'Windows Workstations', index=False)\n",
    "mac_workstations.to_excel(writer, 'Mac Workstations', index=False)\n",
    "cloud_agents.to_excel(writer, 'All Cloud Servers', index=False)\n",
    "cloud_windows.to_excel(writer, 'Cloud Windows Servers', index=False)\n",
    "cloud_linux.to_excel(writer, 'Cloud Linux Servers', index=False)\n",
    "df.to_excel(writer, 'Raw Data', index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Agent Work Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of agent versions that need to be upgraded\n",
    "trouble_group = ['30.19.6', '31.28.4', '30.19.3', '31.28.4', '23.10.0', '26.21.10', '29.7.0', '30.19.3', '30.19.6', '30.19.8', '31.28.4', '31.28.8', '32.30.0', '32.30.10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scrub data so it can be consumed\n",
    "trouble_agents = hosts_df[hosts_df['agent_version'].isin(trouble_group)]\n",
    "trouble_agent_sorted = trouble_agents.sort_values(by=['agent_version'])\n",
    "trouble_agent_trim = trouble_agent_sorted[['_id', 'agent_version', 'hostname', 'domain', 'os.product_name', 'primary_mac', 'timezone', 'initial_agent_checkin', 'last_poll_timestamp', 'stats.acqs', 'stats.alerts']]\n",
    "trouble_agent_trim.drop_duplicates(subset=['hostname'], inplace=True)\n",
    "trouble_agent_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create pivot table of the trouble agent versions\n",
    "pd.options.display.max_rows = 100\n",
    "old_agentos_pivot = pd.pivot_table(trouble_agent_trim.fillna(0), index=['os.product_name', 'agent_version'], aggfunc='count', margins = True)\n",
    "old_agentos_df = old_agentos_pivot['_id']\n",
    "old_agentos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table showing the agent versions and count of the agents in each agent version\n",
    "pd.options.display.max_rows = 100\n",
    "old_agent_pivot = pd.pivot_table(trouble_agent_trim.fillna(0), index=['agent_version'], aggfunc='count', margins = True)\n",
    "old_agent_df = old_agent_pivot['_id']\n",
    "old_agent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create pivot table showing the OS versions for the trouble agents and give a count per OS version\n",
    "pd.options.display.max_rows = 100\n",
    "old_os_pivot = pd.pivot_table(trouble_agent_trim.fillna(0), index=['os.product_name'], aggfunc='count', margins = True)\n",
    "old_os_df = old_os_pivot['_id']\n",
    "old_os_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Excel document with Potive tables and the raw data, each on their own tab\n",
    "writer = pd.ExcelWriter('FireEye Old Agent Version Breakdown 4-13.xlsx', engine='xlsxwriter')\n",
    "old_os_df.to_excel(writer, 'Pivot Tables', startcol=0)\n",
    "old_agentos_df.to_excel(writer, 'Pivot Tables', startcol=4)\n",
    "trouble_agent_trim.to_excel(writer, 'Old Agent Dataset', index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power BI and Bigfix Work Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest hosts present in Power BI reports\n",
    "powerbi_hosts = pd.read_excel('data - date1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new variable that contains hosts that are not found in the powerbi_bosts data\n",
    "oldhosts_filtered = ~trouble_agent_trim['hostname'].isin(powerbi_hosts['SERVER_NAME'])\n",
    "oldhosts_nopbi = trouble_agent_trim[oldhosts_filtered]\n",
    "oldhosts_nopbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Excel doc containing all hosts that do not show up in Power BI reporting\n",
    "oldhosts_nopbi.to_excel('FireEye Old Agents No PBI.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table with the OS versions for the hosts with the oldest agent check in times with counts for each OS\n",
    "pd.options.display.max_rows = 100\n",
    "old_os_pivot = pd.pivot_table(oldhosts_nopbi.fillna(0), index=['os.product_name'], aggfunc='count', margins = True)\n",
    "old_os_df = old_os_pivot['_id']\n",
    "old_os_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable showing all the hosts that are in the Power BI data as well as the trouble agent data\n",
    "oldhosts_filtered = powerbi_hosts['SERVER_NAME'].str.upper().isin(trouble_agent_trim['hostname'].str.upper())\n",
    "oldhosts_enriched = powerbi_hosts[oldhosts_filtered]\n",
    "oldhosts_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the trouble agent and Power BI data\n",
    "pbi_merged = pd.merge(trouble_agent_trim, powerbi_hosts[['SERVER_NAME', 'AIID', 'APPLICATION_NAME','SUPPORT_GROUP', 'CONFIG_ADMIN_GROUP', 'U_SUPPORT_GROUP_L2', 'U_SUPPORT_GROUP_L3', 'RESOURCE_GROUP']],\n",
    "                     left_on='hostname', right_on='SERVER_NAME', how='left')\n",
    "pbi_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deduplicate merged data\n",
    "pbi_merged.drop_duplicates(subset=['hostname'],inplace=True)\n",
    "pbi_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the merged dataset with BigFix data\n",
    "bf_merged = pd.merge(pbi_merged, bigfix_agents_df[['HOSTNAME','PLATFORM_SUPPORT', 'MACADDRESS']],\n",
    "                     left_on=('hostname'), right_on=('HOSTNAME'), how='left')\n",
    "bf_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates for the BigFix merged data\n",
    "bf_merged.drop_duplicates(subset=['hostname'],inplace=True)\n",
    "bf_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Excel doc out of BigFix curated DataFrame\n",
    "bf_merged.to_excel('FireEye merge.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from CSV\n",
    "bigfix_agents_df = pd.read_csv('BigFix-currentdate.csv')\n",
    "bigfix_agents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame size\n",
    "trouble_agent_trim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Stale Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stale_agents = []\n",
    "stale_agents = pd.read_csv('stale_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hx_appliance = LOCAL_APPLIANCE\n",
    "hx_api_object = HXAPI(hx_appliance, hx_port = 3000)\n",
    "# Log into appliance\n",
    "(ret, response_code, response_data) = hx_api_object.restLogin(user_id, pwd)\n",
    "# If login successful, begin deletion process of each agent by ID\n",
    "if ret:\n",
    "    for agent in stale_agents:\n",
    "        (d_ret, d_response_code, d_response_data) = hx_api_object.restDeleteHostByID(agent)\n",
    "        if d_ret:\n",
    "            print(\"[.] Deleted {}\".format(agent))\n",
    "        else:\n",
    "            print(d_ret)\n",
    "            print(\"[!] Failed to delete host {}. Error: {}\".format(agent, d_response_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate hostset and get hosts in a list\n",
    "stale_agent_hostset = hx_api_object.restListHostsInHostset('1111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable with just the hosts and no additional data that comes back \n",
    "data = (stale_agent_hostset[2]['data']['entries'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather just the ID's from the returned data\n",
    "stale_agent_ids = []\n",
    "for agent in data:\n",
    "    stale_agent_ids.append(agent['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pickle file of stale ids\n",
    "pickle.dump( stale_agent_ids, open( \"stale_agents_ids_currentdate.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from stale agent ids\n",
    "stale_df = pd.DataFrame(stale_agent_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV for stale agents\n",
    "stale_df.to_csv('stale_agents_currentdate.csv',header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
